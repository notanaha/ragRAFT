{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import openai\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    VectorizedQuery, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "aoai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "\n",
    "aoai_client = openai.AzureOpenAI( \n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_key=aoai_api_key,\n",
    "    api_version= api_version\n",
    ")\n",
    "    \n",
    "chat_model_ft = os.environ[\"AZURE_OPENAI_CHAT_MODEL_FT\"]\n",
    "embedding_model = os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL\"] \n",
    "\n",
    "service_endpoint = os.environ[\"SEARCH_ENDPOINT\"] \n",
    "key = os.environ[\"SEARCH_KEY\"]\n",
    "search_index_name = os.environ[\"SEARCH_INDEX_NAME\"]\n",
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=search_index_name, credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/*----------------*/\n",
    "#  gpt4_query      */\n",
    "#/*----------------*/\n",
    "def gpt4_ft_query(ft_content, model=chat_model_ft):\n",
    "\n",
    "    messages = []\n",
    "    #messages.append({\"role\": \"system\",\"content\": 'You are an AI assistant that helps people find information.'})\n",
    "    messages.append({\"role\": \"user\", \"content\": ft_content})\n",
    "    response = aoai_client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    #response_format={ \"type\": \"json_object\" },\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    messages.append(response_message)\n",
    "\n",
    "    return response_message, messages\n",
    "\n",
    "\n",
    "def gpt4_query(messages, tools=None, tool_choice=None, model=chat_model_ft):\n",
    "\n",
    "    response = aoai_client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    max_tokens = 4000,\n",
    "    #response_format={ \"type\": \"json_object\" },\n",
    "    tools=tools,\n",
    "    tool_choice=tool_choice\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    messages.append(response_message)\n",
    "\n",
    "    return response_message, messages\n",
    "\n",
    "\n",
    "def call_gpt4(messages, tools=None, tool_choice=None, user_context=None, ft_content=''):\n",
    "\n",
    "    response_message, messages = gpt4_query(messages, tools=tools, tool_choice=tool_choice)\n",
    "\n",
    "    answer     = response_message.content\n",
    "    tool_calls = response_message.tool_calls\n",
    "    #print(\"answer:\", answer)\n",
    "    print(\"tool_calls:\", tool_calls)\n",
    "\n",
    "    if tool_calls:\n",
    "        ft_content = checkandrun_function_calling(tool_calls, messages)\n",
    "        ft_content += '\\n' + user_context\n",
    "        response_message, messages  = gpt4_ft_query(ft_content)\n",
    "    else:\n",
    "        print(\"No tool calls were made by the model.\")\n",
    "\n",
    "    return response_message, messages, ft_content\n",
    "\n",
    "\n",
    "def checkandrun_function_calling(tool_calls, messages, ft_content=''):\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        print(\"function_name: \", function_name)\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        print(\"function_args: \", function_args)\n",
    "\n",
    "        if function_name == \"searchDocuments\":\n",
    "            function_response = searchDocuments(\n",
    "                query=function_args.get(\"query\")\n",
    "            )\n",
    "        else:\n",
    "            function_response = json.dumps({\"error\": \"Unknown function\"})\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  \n",
    "        ft_content += function_response\n",
    "        \n",
    "    return ft_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOOLS DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(text, model, aoai_client):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return aoai_client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "def searchDocuments(query, aoai_client=aoai_client, embedding_model=embedding_model, search_client=search_client):\n",
    "\n",
    "    vector_query = VectorizedQuery(vector=generate_embeddings(query, embedding_model, aoai_client), k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "    results = list(search_client.search(  \n",
    "        search_text=query,  \n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"title\", \"content\"],\n",
    "        query_type=QueryType.SEMANTIC, \n",
    "        semantic_configuration_name=\"default\",\n",
    "        #query_caption=QueryCaptionType.EXTRACTIVE, \n",
    "        #query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "        top=3\n",
    "    ))\n",
    "\n",
    "    concatenated_documents = \"\"\n",
    "    for doc in results:\n",
    "        concatenated_documents += f\"<DOCUMENT>\\nTitle: {doc['title']}\\nContent: {doc['content']}\\n</DOCUMENT>\\n\"\n",
    "    \n",
    "    #concatenated_documents += '\\n' + user_context\n",
    "\n",
    "    return concatenated_documents\n",
    "\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"searchDocuments\",\n",
    "            \"description\": \"Use this to search for documents relevant to the query\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"query string to search for documents. Use the query as it is.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./100_businessSupport_sys_msg01.txt\", \"r\", encoding = 'utf-8') as f:\n",
    "    system_message = f.read()\n",
    "\n",
    "user_context = \"PCS警告灯が点滅または点灯する場合はどうすればよいですか？\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask a quesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_calls: [ChatCompletionMessageToolCall(id='call_GM1yFaXaVdeQu7ikPLELuii6', function=Function(arguments='{\"query\":\"PCS警告灯が点滅または点灯する場合の対処方法\"}', name='searchDocuments'), type='function')]\n",
      "function_name:  searchDocuments\n",
      "function_args:  {'query': 'PCS警告灯が点滅または点灯する場合の対処方法'}\n",
      "### 考え方\n",
      "\n",
      "1. 質問は「PCS警告灯が点滅または点灯する場合の対処法」についてです。\n",
      "2. 文脈の中で「PCS警告灯」に関する情報を探します。\n",
      "3. 文脈内で「PCS警告灯」が点滅または点灯する場合の対処法が記載されている箇所を特定します。\n",
      "4. 必要に応じて、関連する情報を引用し、質問に対する答えを導きます。\n",
      "\n",
      "---\n",
      "\n",
      "### ステップ1: 文脈内で「PCS警告灯」に関する情報を探す\n",
      "\n",
      "文脈内で「PCS警告灯」に関する記述を見つけました。以下の内容が該当します。\n",
      "\n",
      "##begin_quote##\n",
      "PCS 警告灯 · 警告ブザーが鳴った場合: プリクラッシュセーフティの異常 →ただちにトヨタ販売店で点検を受けてください。 · 警告ブザーが鳴らない場合: プリクラッシュセーフティが一時的、または対処を行うまで作動停止している (点滅または点 灯) → マルチインフォメーションディスプレイに表示されている メッセージの指示に従ってください。(→P. 251, 567) プリクラッシュセーフティが OFF、または VSC (ビークル スタビリティコントロール)システムが停止しているときも 点灯します。 → P. 261\n",
      "##end_quote##\n",
      "\n",
      "---\n",
      "\n",
      "### ステップ2: 情報を整理\n",
      "\n",
      "上記の引用から、PCS警告灯が点滅または点灯する場合の対処法は以下の通りです：\n",
      "\n",
      "1. **警告ブザーが鳴る場合**: プリクラッシュセーフティの異常が発生している可能性があるため、ただちにトヨタ販売店で点検を受ける必要があります。\n",
      "2. **警告ブザーが鳴らない場合**: プリクラッシュセーフティが一時的に作動停止している可能性があるため、マルチインフォメーションディスプレイに表示されているメッセージの指示に従う必要があります。\n",
      "\n",
      "---\n",
      "\n",
      "### ステップ3: 答えをまとめる\n",
      "\n",
      "以上の情報を基に、質問に対する答えをまとめます。\n",
      "\n",
      "---\n",
      "\n",
      "<ANSWER>: PCS警告灯が点滅または点灯した場合、まず警告ブザーが鳴っているか確認してください！  \n",
      "- **警告ブザーが鳴っている場合**: プリクラッシュセーフティの異常が考えられるので、ただちにトヨタ販売店で点検を受けてください。  \n",
      "- **警告ブザーが鳴っていない場合**: プリクラッシュセーフティが一時的に作動停止している可能性があります。マルチインフォメーションディスプレイに表示されているメッセージの指示に従ってください。  \n",
      "\n",
      "安全第一で、早めの対応を心がけましょう！ 😊\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\",\"content\": system_message})\n",
    "messages.append({\"role\": \"user\", \"content\": user_context})\n",
    "response_message, messages, ft_content = call_gpt4(messages, tools=tools, tool_choice='auto', user_context=user_context)\n",
    "print(response_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fllow up question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_calls: None\n",
      "No tool calls were made by the model.\n",
      "### 考え方\n",
      "\n",
      "1. 質問は「Search Index から得られたドキュメントの名前を教えてください」という内容です。\n",
      "2. これまでの会話の中で、Search Index から取得したドキュメントが3つあります。それぞれのドキュメントにはタイトルが付けられています。\n",
      "3. これらのタイトルを確認し、リストアップします。\n",
      "\n",
      "---\n",
      "\n",
      "### ステップ1: ドキュメントのタイトルを確認\n",
      "\n",
      "これまでの会話で使用したドキュメントのタイトルは以下の通りです：\n",
      "\n",
      "1. ##begin_quote##Title: prius_60##end_quote##\n",
      "2. ##begin_quote##Title: prius_10##end_quote##\n",
      "3. ##begin_quote##Title: prius_62##end_quote##\n",
      "\n",
      "---\n",
      "\n",
      "### ステップ2: 答えをまとめる\n",
      "\n",
      "以上の情報を基に、質問に対する答えをまとめます。\n",
      "\n",
      "---\n",
      "\n",
      "<ANSWER>: Search Index から得られたドキュメントの名前は以下の3つです！  \n",
      "1. prius_60  \n",
      "2. prius_10  \n",
      "3. prius_62  \n",
      "\n",
      "これらのドキュメントを使って、質問に答えることができました！ 😊\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\",\"content\": \"Search Index から得られたドキュメントの名前を教えてください。?\"})\n",
    "response_message, messages, ft_content = call_gpt4(messages, tools=tools, tool_choice='auto')\n",
    "print(response_message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

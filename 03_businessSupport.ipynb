{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import openai\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import (\n",
    "    QueryType,\n",
    "    VectorizedQuery, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SET VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_endpoint = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "aoai_api_key = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "api_version = os.environ[\"AZURE_OPENAI_API_VERSION\"]\n",
    "\n",
    "aoai_client = openai.AzureOpenAI( \n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    api_key=aoai_api_key,\n",
    "    api_version= api_version\n",
    ")\n",
    "    \n",
    "chat_model_ft = os.environ[\"AZURE_OPENAI_CHAT_MODEL_FT\"]\n",
    "embedding_model = os.environ[\"AZURE_OPENAI_EMBEDDING_MODEL\"] \n",
    "\n",
    "service_endpoint = os.environ[\"SEARCH_ENDPOINT\"] \n",
    "key = os.environ[\"SEARCH_KEY\"]\n",
    "search_index_name = os.environ[\"SEARCH_INDEX_NAME\"]\n",
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=search_index_name, credential=credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/*----------------*/\n",
    "#  gpt4_query      */\n",
    "#/*----------------*/\n",
    "def gpt4_ft_query(ft_content, model=chat_model_ft):\n",
    "\n",
    "    messages = []\n",
    "    #messages.append({\"role\": \"system\",\"content\": 'You are an AI assistant that helps people find information.'})\n",
    "    messages.append({\"role\": \"user\", \"content\": ft_content})\n",
    "    response = aoai_client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    #response_format={ \"type\": \"json_object\" },\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    messages.append(response_message)\n",
    "\n",
    "    return response_message, messages\n",
    "\n",
    "\n",
    "def gpt4_query(messages, tools=None, tool_choice=None, model=chat_model_ft):\n",
    "\n",
    "    response = aoai_client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    max_tokens = 4000,\n",
    "    #response_format={ \"type\": \"json_object\" },\n",
    "    tools=tools,\n",
    "    tool_choice=tool_choice\n",
    "    )\n",
    "\n",
    "    response_message = response.choices[0].message\n",
    "    messages.append(response_message)\n",
    "\n",
    "    return response_message, messages\n",
    "\n",
    "\n",
    "def call_gpt4(messages, tools=None, tool_choice=None, user_context=None, ft_content=''):\n",
    "\n",
    "    response_message, messages = gpt4_query(messages, tools=tools, tool_choice=tool_choice)\n",
    "\n",
    "    answer     = response_message.content\n",
    "    tool_calls = response_message.tool_calls\n",
    "    #print(\"answer:\", answer)\n",
    "    print(\"tool_calls:\", tool_calls)\n",
    "\n",
    "    if tool_calls:\n",
    "        ft_content = checkandrun_function_calling(tool_calls, messages)\n",
    "        ft_content += '\\n' + user_context\n",
    "        response_message, messages  = gpt4_ft_query(ft_content)\n",
    "    else:\n",
    "        print(\"No tool calls were made by the model.\")\n",
    "\n",
    "    return response_message, messages, ft_content\n",
    "\n",
    "\n",
    "def checkandrun_function_calling(tool_calls, messages, ft_content=''):\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        print(\"function_name: \", function_name)\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        print(\"function_args: \", function_args)\n",
    "\n",
    "        if function_name == \"searchDocuments\":\n",
    "            function_response = searchDocuments(\n",
    "                query=function_args.get(\"query\")\n",
    "            )\n",
    "        else:\n",
    "            function_response = json.dumps({\"error\": \"Unknown function\"})\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  \n",
    "        ft_content += function_response\n",
    "        \n",
    "    return ft_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOOLS DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(text, model, aoai_client):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return aoai_client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "\n",
    "def searchDocuments(query, aoai_client=aoai_client, embedding_model=embedding_model, search_client=search_client):\n",
    "\n",
    "    vector_query = VectorizedQuery(vector=generate_embeddings(query, embedding_model, aoai_client), k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "\n",
    "    results = list(search_client.search(  \n",
    "        search_text=query,  \n",
    "        vector_queries=[vector_query],\n",
    "        select=[\"title\", \"content\"],\n",
    "        query_type=QueryType.SEMANTIC, \n",
    "        semantic_configuration_name=\"default\",\n",
    "        #query_caption=QueryCaptionType.EXTRACTIVE, \n",
    "        #query_answer=QueryAnswerType.EXTRACTIVE,\n",
    "        top=3\n",
    "    ))\n",
    "\n",
    "    concatenated_documents = \"\"\n",
    "    for doc in results:\n",
    "        concatenated_documents += f\"<DOCUMENT>\\nTitle: {doc['title']}\\nContent: {doc['content']}\\n</DOCUMENT>\\n\"\n",
    "    \n",
    "    #concatenated_documents += '\\n' + user_context\n",
    "\n",
    "    return concatenated_documents\n",
    "\n",
    "\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"searchDocuments\",\n",
    "            \"description\": \"Use this to search for documents relevant to the query\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"query string to search for documents. Use the query as it is.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\"],\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./100_businessSupport_sys_msg01.txt\", \"r\", encoding = 'utf-8') as f:\n",
    "    system_message = f.read()\n",
    "\n",
    "user_context = \"PCSè­¦å‘Šç¯ãŒç‚¹æ»…ã¾ãŸã¯ç‚¹ç¯ã™ã‚‹å ´åˆã¯ã©ã†ã™ã‚Œã°ã‚ˆã„ã§ã™ã‹ï¼Ÿ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask a quesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_calls: [ChatCompletionMessageToolCall(id='call_GM1yFaXaVdeQu7ikPLELuii6', function=Function(arguments='{\"query\":\"PCSè­¦å‘Šç¯ãŒç‚¹æ»…ã¾ãŸã¯ç‚¹ç¯ã™ã‚‹å ´åˆã®å¯¾å‡¦æ–¹æ³•\"}', name='searchDocuments'), type='function')]\n",
      "function_name:  searchDocuments\n",
      "function_args:  {'query': 'PCSè­¦å‘Šç¯ãŒç‚¹æ»…ã¾ãŸã¯ç‚¹ç¯ã™ã‚‹å ´åˆã®å¯¾å‡¦æ–¹æ³•'}\n",
      "### è€ƒãˆæ–¹\n",
      "\n",
      "1. è³ªå•ã¯ã€ŒPCSè­¦å‘Šç¯ãŒç‚¹æ»…ã¾ãŸã¯ç‚¹ç¯ã™ã‚‹å ´åˆã®å¯¾å‡¦æ³•ã€ã«ã¤ã„ã¦ã§ã™ã€‚\n",
      "2. æ–‡è„ˆã®ä¸­ã§ã€ŒPCSè­¦å‘Šç¯ã€ã«é–¢ã™ã‚‹æƒ…å ±ã‚’æ¢ã—ã¾ã™ã€‚\n",
      "3. æ–‡è„ˆå†…ã§ã€ŒPCSè­¦å‘Šç¯ã€ãŒç‚¹æ»…ã¾ãŸã¯ç‚¹ç¯ã™ã‚‹å ´åˆã®å¯¾å‡¦æ³•ãŒè¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ç®‡æ‰€ã‚’ç‰¹å®šã—ã¾ã™ã€‚\n",
      "4. å¿…è¦ã«å¿œã˜ã¦ã€é–¢é€£ã™ã‚‹æƒ…å ±ã‚’å¼•ç”¨ã—ã€è³ªå•ã«å¯¾ã™ã‚‹ç­”ãˆã‚’å°ãã¾ã™ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ã‚¹ãƒ†ãƒƒãƒ—1: æ–‡è„ˆå†…ã§ã€ŒPCSè­¦å‘Šç¯ã€ã«é–¢ã™ã‚‹æƒ…å ±ã‚’æ¢ã™\n",
      "\n",
      "æ–‡è„ˆå†…ã§ã€ŒPCSè­¦å‘Šç¯ã€ã«é–¢ã™ã‚‹è¨˜è¿°ã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚ä»¥ä¸‹ã®å†…å®¹ãŒè©²å½“ã—ã¾ã™ã€‚\n",
      "\n",
      "##begin_quote##\n",
      "PCS è­¦å‘Šç¯ Â· è­¦å‘Šãƒ–ã‚¶ãƒ¼ãŒé³´ã£ãŸå ´åˆ: ãƒ—ãƒªã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ã®ç•°å¸¸ â†’ãŸã ã¡ã«ãƒˆãƒ¨ã‚¿è²©å£²åº—ã§ç‚¹æ¤œã‚’å—ã‘ã¦ãã ã•ã„ã€‚ Â· è­¦å‘Šãƒ–ã‚¶ãƒ¼ãŒé³´ã‚‰ãªã„å ´åˆ: ãƒ—ãƒªã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãŒä¸€æ™‚çš„ã€ã¾ãŸã¯å¯¾å‡¦ã‚’è¡Œã†ã¾ã§ä½œå‹•åœæ­¢ã—ã¦ã„ã‚‹ (ç‚¹æ»…ã¾ãŸã¯ç‚¹ ç¯) â†’ ãƒãƒ«ãƒã‚¤ãƒ³ãƒ•ã‚©ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æŒ‡ç¤ºã«å¾“ã£ã¦ãã ã•ã„ã€‚(â†’P. 251, 567) ãƒ—ãƒªã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãŒ OFFã€ã¾ãŸã¯ VSC (ãƒ“ãƒ¼ã‚¯ãƒ« ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«)ã‚·ã‚¹ãƒ†ãƒ ãŒåœæ­¢ã—ã¦ã„ã‚‹ã¨ãã‚‚ ç‚¹ç¯ã—ã¾ã™ã€‚ â†’ P. 261\n",
      "##end_quote##\n",
      "\n",
      "---\n",
      "\n",
      "### ã‚¹ãƒ†ãƒƒãƒ—2: æƒ…å ±ã‚’æ•´ç†\n",
      "\n",
      "ä¸Šè¨˜ã®å¼•ç”¨ã‹ã‚‰ã€PCSè­¦å‘Šç¯ãŒç‚¹æ»…ã¾ãŸã¯ç‚¹ç¯ã™ã‚‹å ´åˆã®å¯¾å‡¦æ³•ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š\n",
      "\n",
      "1. **è­¦å‘Šãƒ–ã‚¶ãƒ¼ãŒé³´ã‚‹å ´åˆ**: ãƒ—ãƒªã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ã®ç•°å¸¸ãŒç™ºç”Ÿã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ãŸã ã¡ã«ãƒˆãƒ¨ã‚¿è²©å£²åº—ã§ç‚¹æ¤œã‚’å—ã‘ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
      "2. **è­¦å‘Šãƒ–ã‚¶ãƒ¼ãŒé³´ã‚‰ãªã„å ´åˆ**: ãƒ—ãƒªã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãŒä¸€æ™‚çš„ã«ä½œå‹•åœæ­¢ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ãƒãƒ«ãƒã‚¤ãƒ³ãƒ•ã‚©ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æŒ‡ç¤ºã«å¾“ã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ã‚¹ãƒ†ãƒƒãƒ—3: ç­”ãˆã‚’ã¾ã¨ã‚ã‚‹\n",
      "\n",
      "ä»¥ä¸Šã®æƒ…å ±ã‚’åŸºã«ã€è³ªå•ã«å¯¾ã™ã‚‹ç­”ãˆã‚’ã¾ã¨ã‚ã¾ã™ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "<ANSWER>: PCSè­¦å‘Šç¯ãŒç‚¹æ»…ã¾ãŸã¯ç‚¹ç¯ã—ãŸå ´åˆã€ã¾ãšè­¦å‘Šãƒ–ã‚¶ãƒ¼ãŒé³´ã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ï¼  \n",
      "- **è­¦å‘Šãƒ–ã‚¶ãƒ¼ãŒé³´ã£ã¦ã„ã‚‹å ´åˆ**: ãƒ—ãƒªã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ã®ç•°å¸¸ãŒè€ƒãˆã‚‰ã‚Œã‚‹ã®ã§ã€ãŸã ã¡ã«ãƒˆãƒ¨ã‚¿è²©å£²åº—ã§ç‚¹æ¤œã‚’å—ã‘ã¦ãã ã•ã„ã€‚  \n",
      "- **è­¦å‘Šãƒ–ã‚¶ãƒ¼ãŒé³´ã£ã¦ã„ãªã„å ´åˆ**: ãƒ—ãƒªã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãŒä¸€æ™‚çš„ã«ä½œå‹•åœæ­¢ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒãƒ«ãƒã‚¤ãƒ³ãƒ•ã‚©ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ã‚£ã‚¹ãƒ—ãƒ¬ã‚¤ã«è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æŒ‡ç¤ºã«å¾“ã£ã¦ãã ã•ã„ã€‚  \n",
      "\n",
      "å®‰å…¨ç¬¬ä¸€ã§ã€æ—©ã‚ã®å¯¾å¿œã‚’å¿ƒãŒã‘ã¾ã—ã‚‡ã†ï¼ ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "messages = []\n",
    "messages.append({\"role\": \"system\",\"content\": system_message})\n",
    "messages.append({\"role\": \"user\", \"content\": user_context})\n",
    "response_message, messages, ft_content = call_gpt4(messages, tools=tools, tool_choice='auto', user_context=user_context)\n",
    "print(response_message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fllow up question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool_calls: None\n",
      "No tool calls were made by the model.\n",
      "### è€ƒãˆæ–¹\n",
      "\n",
      "1. è³ªå•ã¯ã€ŒSearch Index ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åå‰ã‚’æ•™ãˆã¦ãã ã•ã„ã€ã¨ã„ã†å†…å®¹ã§ã™ã€‚\n",
      "2. ã“ã‚Œã¾ã§ã®ä¼šè©±ã®ä¸­ã§ã€Search Index ã‹ã‚‰å–å¾—ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒ3ã¤ã‚ã‚Šã¾ã™ã€‚ãã‚Œãã‚Œã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¯ã‚¿ã‚¤ãƒˆãƒ«ãŒä»˜ã‘ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚\n",
      "3. ã“ã‚Œã‚‰ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç¢ºèªã—ã€ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç¢ºèª\n",
      "\n",
      "ã“ã‚Œã¾ã§ã®ä¼šè©±ã§ä½¿ç”¨ã—ãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã‚¿ã‚¤ãƒˆãƒ«ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™ï¼š\n",
      "\n",
      "1. ##begin_quote##Title: prius_60##end_quote##\n",
      "2. ##begin_quote##Title: prius_10##end_quote##\n",
      "3. ##begin_quote##Title: prius_62##end_quote##\n",
      "\n",
      "---\n",
      "\n",
      "### ã‚¹ãƒ†ãƒƒãƒ—2: ç­”ãˆã‚’ã¾ã¨ã‚ã‚‹\n",
      "\n",
      "ä»¥ä¸Šã®æƒ…å ±ã‚’åŸºã«ã€è³ªå•ã«å¯¾ã™ã‚‹ç­”ãˆã‚’ã¾ã¨ã‚ã¾ã™ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "<ANSWER>: Search Index ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åå‰ã¯ä»¥ä¸‹ã®3ã¤ã§ã™ï¼  \n",
      "1. prius_60  \n",
      "2. prius_10  \n",
      "3. prius_62  \n",
      "\n",
      "ã“ã‚Œã‚‰ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½¿ã£ã¦ã€è³ªå•ã«ç­”ãˆã‚‹ã“ã¨ãŒã§ãã¾ã—ãŸï¼ ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "messages.append({\"role\": \"user\",\"content\": \"Search Index ã‹ã‚‰å¾—ã‚‰ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®åå‰ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚?\"})\n",
    "response_message, messages, ft_content = call_gpt4(messages, tools=tools, tool_choice='auto')\n",
    "print(response_message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
